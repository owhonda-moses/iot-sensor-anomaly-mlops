{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af3aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Python 3.11.7\n"
     ]
    }
   ],
   "source": [
    "!poetry run python -m ipykernel install \\\n",
    "  --user \\\n",
    "  --name iot-anomaly \\\n",
    "  --display-name \"Python (iot-anomaly)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8032ef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753196585.404697   12488 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753196585.410360   12488 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753196585.423030   12488 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753196585.423058   12488 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753196585.423060   12488 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753196585.423062   12488 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "# os.environ[\"XLA_FLAGS\"] = \"--tf_xla_enable_xla_devices=false\"\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math, time, pickle, logging, argparse, joblib, sys\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, fbeta_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import optuna\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import save_model, Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d575d9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de5fd11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "# path = \"../data/iot_telemetry_data.csv\"\n",
    "path = \"./data/iot_telemetry_data.csv\"\n",
    "model_dir = \"iot_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\", datefmt=\"%H:%M:%S\")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "662ae5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load CSV data\n",
    "    \"\"\"\n",
    "    logger.info(\"Loading data from %s\", path)\n",
    "    df = pd.read_csv(path)\n",
    "    df['ts'] = pd.to_datetime(df['ts'], unit='s', utc=True)\n",
    "    return df.sort_values('ts').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee74802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add mappings and flag features\n",
    "    \"\"\"\n",
    "    logger.info(\"Adding feature mappings and flags\")\n",
    "    # env/device maps\n",
    "    env_map = {\n",
    "        \"00:0f:00:70:91:0a\": \"stable_cooler_humid\",\n",
    "        \"1c:bf:ce:15:ec:4d\": \"variable_temp_humid\",\n",
    "        \"b8:27:eb:bf:9d:51\": \"stable_warmer_dry\"\n",
    "    }\n",
    "    df['env'] = df['device'].map(env_map)\n",
    "    df['device'] = df['device'].map({k: f\"device_{i+1}\" \n",
    "                                     for i,k in enumerate(env_map)})\n",
    "\n",
    "    # timestamp diffs & duplicates\n",
    "    df['ts_diff'] = df.groupby('device')['ts'] \\\n",
    "                              .diff().dt.total_seconds().fillna(0)\n",
    "    # df['ts_large'] = (df['ts_diff'] > 4).astype(int)\n",
    "    # df['ts_duplicate']= df.duplicated(['device','ts'], keep=False).astype(int)\n",
    "    df = df.drop_duplicates(['device','ts'])\n",
    "\n",
    "    # quantile flags per device for temp & humidity\n",
    "    temp_hum = ['temp','humidity']\n",
    "    quantiles = [0.01, 0.99]\n",
    "    qt = {}\n",
    "    for dev in df['device'].unique():\n",
    "        sub = df[df['device']==dev]\n",
    "        lo, hi = sub[temp_hum].quantile(quantiles).values.T\n",
    "        qt[dev] = dict(temp=(math.floor(lo[0]), math.floor(hi[0])),\n",
    "                       humidity=(math.floor(lo[1]), math.floor(hi[1])))\n",
    "    for feat in temp_hum:\n",
    "        df[f\"{feat}_flag\"] = 0\n",
    "        for dev,(low,high) in [(d,qt[d][feat]) for d in qt]:\n",
    "            mask = (df['device']==dev) & ((df[feat]<low)|(df[feat]>high))\n",
    "            df.loc[mask, f\"{feat}_flag\"] = 1\n",
    "\n",
    "    # gas flags\n",
    "    gas_thr = {'co':0.01, 'lpg':0.01, 'smoke':0.03}\n",
    "    for feat,thr in gas_thr.items():\n",
    "        df[f\"{feat}_flag\"] = (df[feat] > thr).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb3503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Feature encode, model dev preprocessing & scale.\n",
    "    Returns: scaler, X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    logger.info(\"Preprocessing for model training\")\n",
    "    \n",
    "    for col in ['light','motion']:\n",
    "        df[col] = df[col].astype(int)\n",
    "\n",
    "    SENSOR_COLS = ['co','lpg','smoke','temp','humidity']\n",
    "    WINDOW = max(1, int(30 / df.groupby('device')['ts_diff'].median().mean()))\n",
    "    for col in SENSOR_COLS:\n",
    "        roll = df.groupby('device')[col] \\\n",
    "                 .rolling(WINDOW, min_periods=1)\n",
    "        df[f\"{col}_roll_mean\"] = roll.mean().reset_index(level=0, drop=True)\n",
    "        df[f\"{col}_roll_std\"]  = roll.std().fillna(0).reset_index(level=0, drop=True)\n",
    "\n",
    "    secs = (df['ts'].dt.hour * 3600 + df['ts'].dt.minute * 60 + df['ts'].dt.second)\n",
    "    df['tod_sin'] = np.sin(2 * np.pi * secs / 86400)\n",
    "    df['tod_cos'] = np.cos(2 * np.pi * secs / 86400)\n",
    "\n",
    "    base = ['co','humidity','light','motion','lpg','smoke','temp','ts_diff']\n",
    "    rolling_feats = [f\"{c}_{agg}\" for c in SENSOR_COLS for agg in ('roll_mean','roll_std')]\n",
    "    cyclic_feats = ['tod_sin','tod_cos']\n",
    "    env_ohe = pd.get_dummies(df['env'], prefix='', dtype=int)\n",
    "    dev_ohe = pd.get_dummies(df['device'], prefix='', dtype=int)\n",
    "\n",
    "    X = pd.concat([df[base + rolling_feats + cyclic_feats], env_ohe, dev_ohe], axis=1)\n",
    "    X_cols = X.columns.to_list()\n",
    "\n",
    "    flags = ['temp_flag','humidity_flag','co_flag','lpg_flag','smoke_flag']\n",
    "    y = df[flags].any(axis=1).astype(int)\n",
    "    logger.info(\"class counts:\\n%s\", y.value_counts().to_string())\n",
    "\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X.values, y.values, test_size=test_size, shuffle=False, random_state=random_state)\n",
    "\n",
    "    scaler = MinMaxScaler().fit(Xtr)\n",
    "    Xtr = scaler.transform(Xtr)\n",
    "    Xte = scaler.transform(Xte)\n",
    "\n",
    "    return scaler, Xtr, Xte, ytr, yte, X_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dce5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_usl(X_train_norm, X_test, y_test, params, random_state=42):\n",
    "    \"\"\"\n",
    "    Runs IF + (optional) AE, fuses their anomaly scores, \n",
    "    thresholds, and evaluates on y_test.\n",
    "    \"\"\"\n",
    "    # Fit IsolationForest on normals\n",
    "    iso = IsolationForest(\n",
    "        n_estimators = params[\"if_n_estimators\"],\n",
    "        max_samples = params[\"if_max_samples\"],\n",
    "        contamination = params[\"contamination\"],\n",
    "        random_state = random_state\n",
    "    ).fit(X_train_norm)\n",
    "\n",
    "    iso_tr = -iso.decision_function(X_train_norm)\n",
    "    iso_te = -iso.decision_function(X_test)\n",
    "\n",
    "    # Build & train AE only if w_ae > 0\n",
    "    ae_tr = np.zeros_like(iso_tr)\n",
    "    ae_te = np.zeros_like(iso_te)\n",
    "    ae_model = None\n",
    "\n",
    "    if params.get(\"w_ae\", 0) > 0:\n",
    "        input_dim = X_train_norm.shape[1]\n",
    "        enc_dim =  params[\"ae_encoding_dim\"]\n",
    "        lr = params[\"ae_lr\"]\n",
    "\n",
    "        inp = Input(shape=(input_dim,))\n",
    "        x   = Dense(enc_dim*2, activation=\"relu\")(inp)\n",
    "        x   = Dense(enc_dim,   activation=\"relu\")(x)\n",
    "        x   = Dense(enc_dim*2, activation=\"relu\")(x)\n",
    "        out = Dense(input_dim,  activation=\"sigmoid\")(x)\n",
    "\n",
    "        ae_model = Model(inp, out)\n",
    "        ae_model.compile(optimizer=Adam(lr), loss=\"mse\")\n",
    "\n",
    "        ae_model.fit(\n",
    "            X_train_norm, X_train_norm,\n",
    "            epochs = params[\"ae_epochs\"],\n",
    "            batch_size = params[\"ae_batch_size\"],\n",
    "            validation_split = 0.1,\n",
    "            shuffle = True,\n",
    "            verbose = 0\n",
    "        )\n",
    "\n",
    "        Xtr_pred = ae_model.predict(X_train_norm, verbose=0)\n",
    "        ae_tr     = np.mean((Xtr_pred - X_train_norm)**2, axis=1)\n",
    "\n",
    "        Xte_pred = ae_model.predict(X_test, verbose=0)\n",
    "        ae_te     = np.mean((Xte_pred - X_test)**2, axis=1)\n",
    "\n",
    "    # Stack & scale IF+AE scores into [0,1]\n",
    "    mat_tr = np.vstack([iso_tr, ae_tr]).T\n",
    "    mat_te = np.vstack([iso_te, ae_te]).T\n",
    "    score_scaler = MinMaxScaler().fit(mat_tr)\n",
    "    norm_tr = score_scaler.transform(mat_tr)\n",
    "    norm_te = score_scaler.transform(mat_te)\n",
    "\n",
    "    # Fuse & threshold\n",
    "    w_if, w_ae, thr_q = params[\"w_if\"], params[\"w_ae\"], params[\"thr_q\"]\n",
    "    fused_tr = w_if * norm_tr[:,0] + w_ae * norm_tr[:,1]\n",
    "    fused_te = w_if * norm_te[:,0] + w_ae * norm_te[:,1]\n",
    "    thr = np.quantile(fused_tr, thr_q)\n",
    "\n",
    "    # Predict & eval\n",
    "    y_pred = (fused_te >= thr).astype(int)\n",
    "    metrics = {\n",
    "        \"roc_auc\": round(roc_auc_score(y_test, fused_te), 3),\n",
    "        \"precision\": round(precision_score(y_test, y_pred, zero_division=0), 3),\n",
    "        \"recall\": round(recall_score(y_test, y_pred, zero_division=0), 3),\n",
    "        \"f1\": round(f1_score(y_test, y_pred, zero_division=0), 3)\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"iso_model\": iso,\n",
    "        \"ae_model\": ae_model,\n",
    "        \"score_scaler\": score_scaler,\n",
    "        \"threshold\": thr,\n",
    "        \"weights\": {\"if\": w_if, \"ae\": w_ae},\n",
    "        \"fused_scores\": fused_te,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"metrics\": metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f9693d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # USL optimization\n",
    "    p = baseline_params.copy()\n",
    "\n",
    "    p[\"if_n_estimators\"] = trial.suggest_int(\"if_n_estimators\", 50, 500)\n",
    "    p[\"if_max_samples\"]  = trial.suggest_categorical(\"if_max_samples\", [\"auto\", 0.5, 1.0])\n",
    "    p[\"contamination\"]   = trial.suggest_float(\"contamination\", 0.005, 0.1)\n",
    "    p[\"ae_encoding_dim\"] = trial.suggest_categorical(\"ae_encoding_dim\", [8, 16, 32])\n",
    "    p[\"ae_lr\"]           = trial.suggest_loguniform(\"ae_lr\", 1e-4, 1e-2)\n",
    "    p[\"ae_epochs\"]       = trial.suggest_int(\"ae_epochs\", 10, 50)\n",
    "    p[\"ae_batch_size\"]   = trial.suggest_categorical(\"ae_batch_size\", [64, 128, 256])\n",
    "\n",
    "    # fusion weights & threshold\n",
    "    w_if = trial.suggest_float(\"w_if\", 0.0, 1.0)\n",
    "    p[\"w_if\"] = w_if\n",
    "    p[\"w_ae\"] = 1.0 - w_if\n",
    "    p[\"thr_q\"] = trial.suggest_float(\"thr_q\", 0.3, 0.99)\n",
    "\n",
    "    result = train_usl(Xtr_norm, Xte, yte, p)\n",
    "\n",
    "    # return the F1‐score\n",
    "    f1 = result[\"metrics\"][\"f1\"]\n",
    "    trial.set_user_attr(\"roc_auc\", result[\"metrics\"][\"roc_auc\"])\n",
    "    trial.set_user_attr(\"precision\", result[\"metrics\"][\"precision\"])\n",
    "    trial.set_user_attr(\"recall\", result[\"metrics\"][\"recall\"])\n",
    "    logger.info(f\"Trial F1={f1:.3f}\")\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5dd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ssl(X_tr, y_tr, seed_frac, seed_cutoff, self_label_thr, C, hold_out_frac, random_state, n_splits=5):\n",
    "    \"\"\"\n",
    "    5-fold TimeSeriesSplit CV + threshold tuning + final refit (semi-supervised).\n",
    "    \n",
    "    Inputs:\n",
    "      X_tr, y_tr         — your full training arrays\n",
    "      seed_frac          — fraction of high-conf negatives to seed\n",
    "      seed_cutoff        — probability cutoff for RF “negative” seeds\n",
    "      self_label_thr     — threshold for SelfTrainingClassifier’s “criterion='threshold'”\n",
    "      C                  — regularization for LogisticRegression\n",
    "      hold_out_frac      — % of fold-train to hold out for seeding\n",
    "      random_state       — RNG seed\n",
    "      n_splits           — folds in TimeSeriesSplit\n",
    "      \n",
    "    Prints per-fold thr & metrics, returns:\n",
    "      final_model, avg_metrics, avg_thr\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    fold_metrics    = []\n",
    "    fold_thresholds = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tr)):\n",
    "        X_tr_f, y_tr_f   = X_tr[train_idx],   y_tr[train_idx]\n",
    "        X_val_f, y_val_f = X_tr[val_idx],     y_tr[val_idx]\n",
    "\n",
    "        #  split for RF seeder & fit on larger sub-train\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=hold_out_frac, random_state=random_state)\n",
    "        tr2_idx, hold_idx = next(sss.split(X_tr_f, y_tr_f))\n",
    "        seeder = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=random_state, n_jobs=-1)\n",
    "        seeder.fit(X_tr_f[tr2_idx], y_tr_f[tr2_idx])\n",
    "        p_norm_hold = seeder.predict_proba(X_tr_f[hold_idx])[:, 0]\n",
    "        labels = np.full_like(y_tr_f, fill_value=-1) # build partial labels\n",
    "        labels[y_tr_f == 1] = 1\n",
    "\n",
    "        # pick the top seed_frac of hold_idx negatives\n",
    "        neg_idx = hold_idx[(y_tr_f[hold_idx] == 0) & (p_norm_hold >= seed_cutoff)]\n",
    "        n_seed  = max(1, int(np.ceil(seed_frac * len(neg_idx))))\n",
    "        rng     = np.random.default_rng(random_state)\n",
    "        seed_neg = rng.choice(neg_idx, size=n_seed, replace=False)\n",
    "        labels[seed_neg] = 0\n",
    "\n",
    "        # oversample labeled points & append unlabeled for self-training\n",
    "        lab_idx = np.where(labels >= 0)[0]\n",
    "        X_lab, y_lab = X_tr_f[lab_idx], labels[lab_idx]\n",
    "        ros = RandomOverSampler(random_state=random_state)\n",
    "        X_lab_os, y_lab_os = ros.fit_resample(X_lab, y_lab)\n",
    "        unlab_idx   = np.where(labels == -1)[0]\n",
    "        X_aug       = np.vstack([X_lab_os, X_tr_f[unlab_idx]])\n",
    "        labels_aug  = np.concatenate([y_lab_os, labels[unlab_idx]])\n",
    "\n",
    "        # self-train \n",
    "        base_clf = LogisticRegression(C=C, solver='saga', class_weight='balanced', max_iter=1000, random_state=random_state, n_jobs=-1)\n",
    "        # base_clf = model = RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1, random_state=random_state)\n",
    "        self_train = SelfTrainingClassifier(\n",
    "            base_estimator=base_clf,\n",
    "            criterion='threshold',\n",
    "            threshold=self_label_thr,\n",
    "            max_iter=10,\n",
    "            verbose=False\n",
    "        )\n",
    "        self_train.fit(X_aug, labels_aug)\n",
    "\n",
    "        # threshold sweep on val set\n",
    "        probs_val  = self_train.predict_proba(X_val_f)[:,1]\n",
    "        ths        = np.linspace(0.10, 0.99, 90)\n",
    "        f1s        = [f1_score(y_val_f, probs_val>=t) for t in ths]\n",
    "        best_i     = int(np.argmax(f1s))\n",
    "        best_t     = ths[best_i]\n",
    "\n",
    "        y_pred_f = (probs_val >= best_t).astype(int)\n",
    "        metrics  = {\n",
    "            \"roc_auc\":   roc_auc_score(y_val_f, probs_val),\n",
    "            \"precision\": precision_score(y_val_f, y_pred_f, zero_division=0),\n",
    "            \"recall\":    recall_score(y_val_f, y_pred_f),\n",
    "            \"f1\":        f1s[best_i]\n",
    "        }\n",
    "\n",
    "        fold_metrics.append(metrics)\n",
    "        fold_thresholds.append(best_t)\n",
    "        logger.info(f\"Fold {fold}: thr={best_t:.3f}, f1={metrics['f1']:.3f}\")\n",
    "\n",
    "    # aggregate CV results\n",
    "    avg_metrics = {\n",
    "        k: np.mean([m[k] for m in fold_metrics])\n",
    "        for k in fold_metrics[0]\n",
    "    }\n",
    "    avg_thr = float(np.mean(fold_thresholds))\n",
    "    logger.info(\n",
    "        \"Average CV metrics: %s   Average thr: %.3f\",\n",
    "        avg_metrics, avg_thr\n",
    "    )\n",
    "\n",
    "    # final seeding + self-train on X_tr, y_tr\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=hold_out_frac, random_state=random_state)\n",
    "    tr2_idx, hold_idx = next(sss.split(X_tr, y_tr))\n",
    "    seeder = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=random_state, n_jobs=-1)\n",
    "    seeder.fit(X_tr[tr2_idx], y_tr[tr2_idx])\n",
    "    p_norm_hold = seeder.predict_proba(X_tr[hold_idx])[:, 0]\n",
    "\n",
    "    labels = np.full_like(y_tr, fill_value=-1)\n",
    "    labels[y_tr == 1] = 1\n",
    "    neg_idx = hold_idx[(y_tr[hold_idx] == 0) & (p_norm_hold >= seed_cutoff)]\n",
    "    n_seed  = max(1, int(np.ceil(seed_frac * len(neg_idx))))\n",
    "    rng     = np.random.default_rng(random_state)\n",
    "    seed_neg = rng.choice(neg_idx, size=n_seed, replace=False)\n",
    "    labels[seed_neg] = 0\n",
    "\n",
    "    lab_idx = np.where(labels >= 0)[0]\n",
    "    X_lab, y_lab = X_tr[lab_idx], labels[lab_idx]\n",
    "    ros = RandomOverSampler(random_state=random_state)\n",
    "    X_lab_os, y_lab_os = ros.fit_resample(X_lab, y_lab)\n",
    "\n",
    "    unlab_idx  = np.where(labels == -1)[0]\n",
    "    X_aug      = np.vstack([X_lab_os, X_tr[unlab_idx]])\n",
    "    labels_aug = np.concatenate([y_lab_os, labels[unlab_idx]])\n",
    "\n",
    "    base_clf = LogisticRegression(C=C, solver='saga', class_weight='balanced', max_iter=1000, random_state=random_state, n_jobs=1)\n",
    "    # base_clf = model = RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=1, random_state=random_state)\n",
    "    final_model = SelfTrainingClassifier(\n",
    "        base_estimator=base_clf,\n",
    "        criterion='threshold',\n",
    "        threshold=self_label_thr,\n",
    "        max_iter=10,\n",
    "        verbose=False\n",
    "    ).fit(X_aug, labels_aug)\n",
    "\n",
    "    return final_model, avg_metrics, avg_thr\n",
    "\n",
    "\n",
    "# RUN\n",
    "final_model, avg_metrics, avg_thr = train_ssl(\n",
    "    Xtr, ytr,\n",
    "    seed_frac=0.30,\n",
    "    seed_cutoff=0.90,\n",
    "    self_label_thr=0.95,\n",
    "    C=1.0,\n",
    "    hold_out_frac=0.10,\n",
    "    random_state=42,\n",
    "    n_splits=5\n",
    ")\n",
    "\n",
    "probs_test = final_model.predict_proba(Xte)[:,1]\n",
    "y_pred     = (probs_test >= avg_thr).astype(int)\n",
    "\n",
    "print(\"Test  roc_auc:\",   roc_auc_score(yte, probs_test))\n",
    "print(\"Test  precision:\", precision_score(yte, y_pred, zero_division=0))\n",
    "print(\"Test  recall   :\", recall_score(yte, y_pred))\n",
    "print(\"Test  F1       :\", f1_score(yte, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa1fd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sl(X_tr, y_tr, X_te, y_te, C, tol, penalty, random_state, n_splits=5):\n",
    "    \"\"\"\n",
    "    TimeSeriesSplit CV + threshold tuning + final refit.\n",
    "\n",
    "    Inputs:\n",
    "      X_tr, y_tr      — full train arrays\n",
    "      C               — LR regularization param\n",
    "      random_state    — for sampler & LR\n",
    "      n_splits        — number of TS folds\n",
    "\n",
    "    Prints per-fold thr & metrics, returns:\n",
    "      final_model, avg_metrics_dict, avg_thr\n",
    "    \"\"\"\n",
    "    ros = RandomOverSampler(random_state=random_state)\n",
    "    X_tr_os_all, y_tr_os_all = ros.fit_resample(X_tr, y_tr)\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    fold_metrics    = []\n",
    "    fold_thresholds = []\n",
    "    \n",
    "    for train_idx, val_idx in tscv.split(X_tr):\n",
    "        mask = np.isin(ros.sample_indices_, train_idx)\n",
    "        X_tr_os, y_tr_os = X_tr_os_all[mask], y_tr_os_all[mask]\n",
    "        X_val_f, y_val_f = X_tr[val_idx], y_tr[val_idx]\n",
    "\n",
    "        model = LogisticRegression(C=C, solver=\"liblinear\", class_weight=\"balanced\", max_iter=100, warm_start=True,\n",
    "                                   tol=tol, penalty=penalty, n_jobs=-1, random_state=random_state)\n",
    "        # model = RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=1, random_state=random_state)\n",
    "        model.fit(X_tr_os, y_tr_os)\n",
    "\n",
    "        # sweep threshold on fold’s val\n",
    "        probs  = model.predict_proba(X_val_f)[:,1]\n",
    "        thresholds = np.linspace(0.10, 0.99, 90)\n",
    "        f05s = [fbeta_score(y_val_f, probs>=t, beta=0.5) for t in thresholds]\n",
    "        f1s = [f1_score(y_val_f, probs>=t) for t in thresholds]\n",
    "        best_i = int(np.argmax(f1s))\n",
    "        best_t = thresholds[best_i]\n",
    "        best_f05 = f05s[best_i]\n",
    "\n",
    "        y_pred = (probs >= best_t).astype(int)\n",
    "        metrics = {\n",
    "            \"roc_auc\":   round(roc_auc_score(y_val_f, probs), 3),\n",
    "            \"precision\": round(precision_score(y_val_f, y_pred, zero_division=0), 3),\n",
    "            \"recall\":    round(recall_score(y_val_f, y_pred, zero_division=0), 3),\n",
    "            \"f1\":        round(f1s[best_i], 3),\n",
    "            \"f05\":       round(best_f05, 3)\n",
    "        }\n",
    "        fold_metrics.append(metrics)\n",
    "        fold_thresholds.append(best_t)\n",
    "        # logger.info(f\"Fold {fold}: thr={best_t:.3f}, f1={metrics['f1']:.3f}\")\n",
    "\n",
    "    # aggregate\n",
    "    avg_metrics = {\n",
    "        k: round(np.mean([m[k] for m in fold_metrics]), 3)\n",
    "        for k in fold_metrics[0]\n",
    "    }\n",
    "    avg_thr = round(float(np.mean(fold_thresholds)), 3)\n",
    "    \n",
    "    # final oversampled refit on full train\n",
    "    ros_full  = RandomOverSampler(random_state=random_state)\n",
    "    X_full_os, y_full_os = ros_full.fit_resample(X_tr, y_tr)\n",
    "    logger.info(\"Fitting model on oversampled train set\")\n",
    "    final_model = LogisticRegression(C=C, solver=\"liblinear\", class_weight=\"balanced\", max_iter=100, warm_start=True, \n",
    "                                     tol=tol, penalty=penalty, n_jobs=-1, random_state=random_state)\n",
    "    # final_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=1, random_state=random_state)\n",
    "    final_model.fit(X_full_os, y_full_os)\n",
    "\n",
    "    # evaluate on test set\n",
    "    probs_test = final_model.predict_proba(X_te)[:,1]\n",
    "    y_test_pred = (probs_test >= avg_thr).astype(int)\n",
    "    test_metrics = {\n",
    "        \"roc_auc\":   round(roc_auc_score(y_te, probs_test), 3),\n",
    "        \"precision\": round(precision_score(y_te, y_test_pred, zero_division=0), 3),\n",
    "        \"recall\":    round(recall_score(y_te, y_test_pred, zero_division=0), 3),\n",
    "        \"f1\":        round(f1_score(y_te, y_test_pred), 3),\n",
    "        \"f05\":      round(fbeta_score(y_te, y_test_pred, beta=0.5), 3)\n",
    "    }\n",
    "    # logger.info(f\"CV metrics: {avg_metrics} ‖ thr: {avg_thr}\")\n",
    "    # logger.info(f\"SL metrics: {test_metrics}\")\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"model\":        final_model,\n",
    "        \"avg_metrics\":  avg_metrics,\n",
    "        \"avg_thr\":      avg_thr,\n",
    "        \"test_metrics\": test_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b970e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Supervised learning optimization\n",
    "    penalty = trial.suggest_categorical(\"penalty\", [\"l1\",\"l2\"])\n",
    "    C = trial.suggest_loguniform(\"C\", 1e-3, 1e2)\n",
    "    tol = trial.suggest_loguniform(\"tol\", 1e-4, 1e-2)\n",
    "\n",
    "    res = train_sl(\n",
    "        X_tr=Xtr,  y_tr=ytr,\n",
    "        X_te=Xte,  y_te=yte,\n",
    "        C=C,\n",
    "        tol=tol,\n",
    "        penalty=penalty,\n",
    "        random_state=42,\n",
    "        n_splits=5\n",
    "    )\n",
    "    # save CV metrics & threshold\n",
    "    trial.set_user_attr(\"cv_metrics\", res[\"avg_metrics\"])\n",
    "    trial.set_user_attr(\"cv_thr\",     res[\"avg_thr\"])\n",
    "    return res[\"avg_metrics\"][\"f1\"] # optimize CV F1\n",
    "\n",
    "# run\n",
    "# study = optuna.create_study(direction=\"maximize\", study_name=\"iot-anomaly2\", \n",
    "#                             sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "# logger.info(\"Starting Optuna search with %d trials\", optuna_trials)\n",
    "# pbar = tqdm(total=optuna_trials, desc=\"SL-LR tuning\")\n",
    "# def tqdm_callback(study, trial):\n",
    "#     pbar.update(1)\n",
    "#     pbar.set_postfix(best_f1=f\"{study.best_value:.3f}\")\n",
    "# study.optimize(objective, n_trials=optuna_trials, n_jobs=4, callbacks=[tqdm_callback])\n",
    "# pbar.close()\n",
    "\n",
    "# # extract best params & metrics\n",
    "# best_params = study.best_params\n",
    "# best_cv = study.best_trial.user_attrs[\"cv_metrics\"]\n",
    "# best_thr = study.best_trial.user_attrs[\"cv_thr\"]\n",
    "# best_f1 = study.best_value\n",
    "\n",
    "# logger.info(\"params %s\", best_params)\n",
    "# logger.info(\"metrics %s\", best_cv)\n",
    "# logger.info(\"thr %s\", best_thr)\n",
    "# logger.info(\"best CV F1 %s\", best_f1)\n",
    "\n",
    "# # final evaluation on test\n",
    "# logger.info(\"Starting final evaluation on test set\")\n",
    "# final_res = train_sl(\n",
    "#     X_tr=Xtr,  y_tr=ytr,\n",
    "#     X_te=Xte,  y_te=yte,\n",
    "#     **best_params, random_state=42, n_splits=5\n",
    "# )\n",
    "# logger.info(\"Final test metrics: %s\", final_res[\"test_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0964725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_artifacts(usl_base: dict, sl_base: dict, sl_base_params: dict, \n",
    "                   usl_opt: dict, sl_opt: dict, sl_opt_params: dict, scaler, model_dir: str = \"iot_models\"):\n",
    "    \"\"\"\n",
    "    Persist baseline and optimized USL+SL artifacts under:\n",
    "      model_dir/baseline/...  \n",
    "      model_dir/optimized/...\n",
    "    \"\"\"\n",
    "    for tag, usl_res, sl_res, sl_params in [\n",
    "        (\"baseline\", usl_base, sl_base, sl_base_params), (\"optimized\", usl_opt,  sl_opt,  sl_opt_params)\n",
    "        ]:\n",
    "        out_dir = os.path.join(model_dir, tag)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        joblib.dump(scaler, os.path.join(out_dir, \"scaler.pkl\")) # scaler\n",
    "        with open(os.path.join(out_dir, \"iso.pkl\"), \"wb\") as f: # IF\n",
    "            pickle.dump(usl_res[\"iso_model\"], f)\n",
    "        ae = usl_res.get(\"ae_model\") # Autoencoder\n",
    "        if ae is not None:\n",
    "            save_model(ae, os.path.join(out_dir, \"autoencoder.keras\"))\n",
    "        ensemble_meta = {\"weights\": usl_res[\"weights\"], \"threshold\": float(usl_res[\"threshold\"])} # ensemble metadata\n",
    "        with open(os.path.join(out_dir, \"ensemble.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(ensemble_meta, f)\n",
    "\n",
    "        # supervised model\n",
    "        joblib.dump(sl_res[\"model\"], os.path.join(out_dir, \"sl_model.pkl\"))\n",
    "        sl_meta = {\"threshold\": sl_res[\"avg_thr\"], \"metrics\": sl_res[\"test_metrics\"], \"params\": sl_params} # SL metadata\n",
    "        with open(os.path.join(out_dir, \"sl_meta.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(sl_meta, f)\n",
    "        logger.info(f\"{tag.capitalize()} artifacts saved to {out_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53831c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsupervised training configs\n",
    "baseline_params = {\"if_n_estimators\": 100, \"if_max_samples\": \"auto\", \"contamination\": 0.01, # IF\n",
    "                   \"ae_encoding_dim\": 16, \"ae_lr\": 1e-3, \"ae_epochs\": 30, \"ae_batch_size\": 128, # AE\n",
    "                   \"w_if\": 1, \"w_ae\": 0, \"thr_q\": 0.95 # fuse & threshold\n",
    "}\n",
    "# unsupervised tuned params\n",
    "best_usl = {'if_n_estimators': 148, 'if_max_samples': 1.0, 'contamination': 0.07513614867821206, \n",
    "     'ae_encoding_dim': 8, 'ae_lr': 0.0004484570984975867, 'ae_epochs': 43, 'ae_batch_size': 64, \n",
    "     'w_if': 0.6582947205466332, 'thr_q': 0.9691031375838758}\n",
    "best_usl['w_ae'] = 1.0 - best_usl['w_if']\n",
    "for k,v in baseline_params.items():\n",
    "    best_usl.setdefault(k, v)\n",
    "\n",
    "# self-supervised learning configs\n",
    "seed_frac = 0.30     \n",
    "seed_cutoff = 0.90   \n",
    "self_label_thr = 0.95 # self train only pseudo-labels if P ≥ 0.95\n",
    "C = 1.0      \n",
    "hold_out_frac = 0.10     \n",
    "random_state = 42\n",
    "# self-supervised tuned params\n",
    "best_ssl = {'seed_frac': 0.4977861415038456, 'seed_cutoff': 0.96479545707897, \n",
    "        'self_label_thr': 0.8885603176584045, 'C': 7.259464506582171, 'hold_out_frac': 0.2419865414435976}\n",
    "\n",
    "# supervised learning configs\n",
    "sl_base_params = {\"C\": 1.0, \"tol\": 1e-4, \"penalty\": \"l2\"}\n",
    "# supervised tuned params\n",
    "# best_sl = {'penalty': 'l1', 'C': 11.197186694112919, 'tol': 0.00021993710180958864} #hi\n",
    "best_sl = {'penalty': 'l2', 'C': 5.232594029557045, 'tol': 0.002263077789430857} #lo\n",
    "\n",
    "optuna_trials = 100\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6b127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:04:48 INFO Loading data from ./data/iot_telemetry_data.csv\n",
      "02:04:49 INFO Adding feature mappings and flags\n",
      "02:04:49 INFO Preprocessing for model training\n",
      "02:04:50 INFO class counts:\n",
      "0    388893\n",
      "1     16278\n",
      "02:04:51 INFO == Baseline USL ==\n",
      "02:04:53 INFO Baseline USL metrics: {'roc_auc': 0.481, 'precision': 0.026, 'recall': 0.019, 'f1': 0.022}\n",
      "02:04:53 INFO Skipping USL tuning; using best_usl: {'if_n_estimators': 148, 'if_max_samples': 1.0, 'contamination': 0.07513614867821206, 'ae_encoding_dim': 8, 'ae_lr': 0.0004484570984975867, 'ae_epochs': 43, 'ae_batch_size': 64, 'w_if': 0.6582947205466332, 'thr_q': 0.9691031375838758, 'w_ae': 0.3417052794533668}\n",
      "02:04:53 INFO == Optimized USL ==\n",
      "I0000 00:00:1752977115.809770    2562 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14401 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:00:05.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752977117.460490    2614 service.cc:152] XLA service 0x7fc130003c30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1752977117.460520    2614 service.cc:160]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "I0000 00:00:1752977117.642020    2614 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1752977118.980647    2614 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "02:10:47 INFO Optimized USL metrics: {'roc_auc': 0.853, 'precision': 0.207, 'recall': 0.551, 'f1': 0.301}\n",
      "02:10:47 INFO == Baseline SL ==\n",
      "02:11:49 INFO Fitting model on oversampled train set\n",
      "02:12:19 INFO Baseline SL test metrics: {'roc_auc': 0.98, 'precision': 0.494, 'recall': 0.838, 'f1': 0.622, 'f05': 0.538}\n",
      "02:12:19 INFO Skipping SL tuning; using best_sl: {'penalty': 'l2', 'C': 5.232594029557045, 'tol': 0.002263077789430857}\n",
      "02:12:19 INFO == SL OPTIMIZED ==\n",
      "02:13:35 INFO Fitting model on oversampled train set\n",
      "02:14:07 INFO Optimized SL test metrics: {'roc_auc': 0.983, 'precision': 0.761, 'recall': 0.819, 'f1': 0.789, 'f05': 0.772}\n",
      "02:14:07 INFO Baseline artifacts saved to iot_models/baseline\n",
      "02:14:07 INFO Optimized artifacts saved to iot_models/optimized\n",
      "02:14:07 INFO Runtime: 9.32 minutes\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--run_optuna_usl\", action=\"store_true\")\n",
    "    parser.add_argument(\"--run_optuna_sl\", action=\"store_true\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    start = time.time()\n",
    "    # load & preprocess\n",
    "    df = load_data(path)\n",
    "    df = engineer_flags(df)\n",
    "    scaler, Xtr, Xte, ytr, yte, X_cols = preprocess(df)\n",
    "    Xtr_norm = Xtr[ytr == 0]  # normals only for USL\n",
    "\n",
    "    # USL\n",
    "    logger.info(\"== Baseline USL ==\")\n",
    "    usl_base = train_usl(Xtr_norm, Xte, yte, baseline_params)\n",
    "    logger.info(\"Baseline USL metrics: %s\", usl_base[\"metrics\"])\n",
    "    if args.run_optuna_usl: # USL tuning\n",
    "        logger.info(\"Starting USL tuning with %d trials\", optuna_trials)\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "        pbar = tqdm(total=optuna_trials, desc=\"USL tuning\")\n",
    "        for _ in range(optuna_trials):\n",
    "            study.optimize(objective, n_trials=1)\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(best_f1=f\"{study.best_value:.3f}\")\n",
    "        pbar.close()\n",
    "        usl_best = study.best_trial.params\n",
    "        for k, v in baseline_params.items(): # back-fill defaults\n",
    "            usl_best.setdefault(k, v)\n",
    "        logger.info(\"Optimized USL params: %s\", usl_best)\n",
    "    else:\n",
    "        usl_best = best_usl\n",
    "        logger.info(\"Skipping USL tuning; using best_usl: %s\", usl_best)\n",
    "    # USL final\n",
    "    logger.info(\"== Optimized USL ==\")\n",
    "    usl_opt = train_usl(Xtr_norm, Xte, yte, usl_best)\n",
    "    logger.info(\"Optimized USL metrics: %s\", usl_opt[\"metrics\"])\n",
    "\n",
    "    # SL\n",
    "    logger.info(\"== Baseline SL ==\")\n",
    "    sl_base = train_sl(X_tr=Xtr, y_tr=ytr, X_te=Xte, y_te=yte,\n",
    "                        **sl_base_params, random_state=seed, n_splits=5)\n",
    "    logger.info(\"Baseline SL test metrics: %s\", sl_base[\"test_metrics\"])\n",
    "    if args.run_optuna_sl: # SL tuning\n",
    "        logger.info(\"Starting SL tuning with %d trials\", optuna_trials)\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "        pbar = tqdm(total=optuna_trials, desc=\"SL tuning\")\n",
    "        study.optimize(objective, n_trials=optuna_trials, n_jobs=4,\n",
    "                       callbacks=[lambda s, t: (pbar.update(1), pbar.set_postfix(best_f1=f\"{s.best_value:.4f}\"))])\n",
    "        pbar.close()\n",
    "        sl_best = study.best_trial.params\n",
    "        logger.info(\"Optimized SL params: %s\", sl_best)\n",
    "    else:\n",
    "        sl_best = best_sl\n",
    "        logger.info(\"Skipping SL tuning; using best_sl: %s\", sl_best)\n",
    "    # SL final\n",
    "    logger.info(\"== SL OPTIMIZED ==\")\n",
    "    sl_opt = train_sl(X_tr=Xtr,y_tr=ytr, X_te=Xte, y_te=yte,\n",
    "            **sl_best, random_state=seed, n_splits=5)\n",
    "    logger.info(\"Optimized SL test metrics: %s\", sl_opt[\"test_metrics\"])\n",
    "\n",
    "    # save artifacts\n",
    "    save_artifacts(usl_base=usl_base, sl_base=sl_base, sl_base_params=sl_base_params,\n",
    "                   usl_opt=usl_opt, sl_opt=sl_opt, sl_opt_params=sl_best, scaler=scaler,\n",
    "                   model_dir=model_dir\n",
    "                   )\n",
    "    end = time.time()\n",
    "    logger.info(\"Runtime: %.2f minutes\", (end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5484c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5093f5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778387d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8182da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'roc_auc': 0.983, 'precision': 0.761, 'recall': 0.819, 'f1': 0.789, 'f05': 0.772}\n",
    "{'penalty': 'l2', 'C': 5.232594029557045, 'tol': 0.002263077789430857}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b6aca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev = device_1.copy()\n",
    "# time_anomalies = dev[dev['ts_diff'] <= 4]\n",
    "# print(time_anomalies['ts_diff'].count())\n",
    "# print(f'sum:{dev.shape[0]}')\n",
    "\n",
    "# features = ['temp', 'humidity', 'co', 'lpg', 'smoke']\n",
    "# low_qt = 0.01\n",
    "# high_qt = 0.99\n",
    "\n",
    "# for device_name in df['device'].unique():\n",
    "#     device_df = df[df['device'] == device_name]\n",
    "#     # print(f\"\\n__{device_name} (sum: {device_df[feature].count()})__\")\n",
    "#     for feature in features:\n",
    "#         low_q = device_df[feature].quantile(low_qt)\n",
    "#         high_q = device_df[feature].quantile(high_qt)\n",
    "#         mean_val = device_df[feature].mean()\n",
    "        \n",
    "#         lowQ_count = device_df[(device_df[feature] < low_q)][feature].count()\n",
    "#         highQ_count = device_df[(device_df[feature] > high_q)][feature].count()\n",
    "        \n",
    "        # print(\n",
    "        #     f\"\\n{feature}\\n\"\n",
    "        #     f\"  1st: {low_q:.2f} | 99th: {high_q:.2f}\\n\"\n",
    "        #     f\"  Mean: {mean_val:.3f}\\n\"\n",
    "        #     f\"  <1st_Q: {lowQ_count} | >99th_Q: {highQ_count}\")\n",
    "\n",
    "#VIZ\n",
    "# dd = df.copy()\n",
    "# dd['hour'] = dd['ts'].dt.hour\n",
    "# dd['min'] = dd['ts'].dt.hour * 60 + dd['ts'].dt.minute\n",
    "\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# ft = 'temp'\n",
    "\n",
    "# sns.lineplot(data=dd, x='hour', y=ft, hue='device', estimator='mean', errorbar='sd')\n",
    "# # sns.scatterplot(data=dd, x='humidity', y=ft, hue='device', alpha=0.5)\n",
    "\n",
    "# plt.title(f'Avg {ft} per day')\n",
    "# plt.xlabel('hour')\n",
    "# plt.ylabel(f'{ft}')\n",
    "# plt.legend(title=None)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# score_fused = results[\"fused_score\"]\n",
    "# thr = results[\"threshold\"]\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plt.hist(score_fused[y_test == 0], bins=50, alpha=0.6, color='C0', label='Normal (y=0)') # normals\n",
    "# plt.hist(score_fused[y_test == 1], bins=50, alpha=0.6, color='C3', label='Anomaly (y=1)') # anomalies\n",
    "# plt.axvline(thr, color='red', linestyle='--', linewidth=2, label=f\"Threshold = {thr:.3f}\") # threshold line\n",
    "\n",
    "# plt.yscale('log')\n",
    "# plt.title(\"Distribution of Fused Anomaly Scores by Class\")\n",
    "# plt.xlabel(\"Fused Anomaly Score\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.legend()\n",
    "# plt.grid(alpha=0.3)\n",
    "# plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
